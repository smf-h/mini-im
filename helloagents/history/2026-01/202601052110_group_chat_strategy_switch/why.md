# 群聊策略切换（策略1 + 策略2）- 变更提案

## 1. 背景

当前群聊发送的主要瓶颈来自“写扩散”：发送端每发一条消息，服务端需要对群成员做路由查询并逐个下发。当群规模上升（千人/万人群）或在线人数激增时，会导致 Redis/QPS、Netty 写放大、跨实例转发放大以及尾延迟显著变差。

本提案目标是在不引入“群在线集合”等额外索引的前提下（仅缓存群成员全量 userId 集合），通过“按群规模 + 在线人数”动态选择两种策略，尽量降低写扩散，同时保持小群体验。

## 2. 目标与成功标准

### 2.1 目标
- 支持两类群聊下发策略，并自动切换：
  - **策略1（逻辑扇出/按实例分组推送）**：小群或在线不多时，在线成员即时收到。
  - **策略2（读扩散/通知后拉取）**：大群或在线很多时，不推消息体，仅推“新消息通知”，客户端收到后自行拉取。
- 增加“极端兜底”：在线人数非常大时，**降级为不推通知**（仅落库，客户端靠 Sync/Pull 拉取）。
- 约束：不维护群在线集合；群成员集合缓存不区分在线/离线，仅用于成员枚举。

### 2.2 成功标准
- 在群规模/在线人数上升时，单条群消息的 Redis 交互从“逐成员多次 GET”降低为“批量路由查询 + 按实例分组少量 publish/本地批量写”。
- 在大群场景下，服务端不再对每个在线用户推送消息体（只推轻量通知或直接不推）。
- 推送失败语义为 best-effort：离线/断线由客户端拉取兜底，避免服务端“定时任务重发”。

## 3. 范围与非目标

### 3.1 范围内
- 群消息下发链路（成员枚举、路由批查、按 serverId 分组、批量推送/批量通知、兜底降级）。
- 策略选择参数（阈值）配置化，默认值可直接使用。
- 保证“同一发送者连续发送多条群消息时，接收端尽量不乱序”的配套改造可与本提案并行推进（见相关方案包）。

### 3.2 范围外（本次不做）
- 建立“群在线集合/群在线路由索引”（连接上下线维护 set/zset）。
- 万人以上大群的完全读扩散体系（Topic + 分片拉取 + 消息分区存储）与复杂 ACK 回执模型。
- 客户端完整多端同步/已读回执体系（可后续单独立项）。

## 4. 已确认决策（来自当前对话）
- 在线人数口径：`1A`（按在线用户数，同一 user 多端算 1）。
- 阈值：`2默认`（采用默认阈值，可配置）。
- 策略2通知语义：`3B`（推“新消息通知”，客户端再拉取）。
- 兜底：当在线人数过大时，自动降级为 `3A`（不推通知，仅落库，靠拉取）。

