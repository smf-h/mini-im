# 2026-01-08 性能/可用性快测记录（单机）

本记录用于复现与回归验证，不代表生产容量上限。

## 环境与约束

- Windows 单机
- 后端：Spring Boot + Netty WS
- 依赖：本机 MySQL/Redis 已运行（若 MySQL 账号有密码，需设置 `IM_MYSQL_PASSWORD` 或启动参数覆盖 datasource）
- 网络限制：可访问 `api.github.com`，但无法访问 `github.com`；因此 k6 二进制无法通过 GitHub release 直链获取

## 关键结论（本次实测）

### 可靠性（离线/补发）

- 使用仓库自带脚本 `scripts/ws-smoke-test/run.ps1` 对默认实例（`ws://127.0.0.1:9001/ws`）执行：
  - 失败场景：
    - `offline_drop_and_recover`（等待补发超时）
    - `cron_resend_no_ack_receive`（等待补发超时）
  - 结论：当 `im.cron.resend.enabled=false`（默认）时，“兜底补发/离线上线补发”链路不会生效（符合配置预期，但会导致可靠性测试失败）。
- 启动第二实例并开启 `im.cron.resend.enabled=true`（fixed-delay=2000ms）后，对 `ws://127.0.0.1:9002/ws` 再次执行同脚本：
  - 所有场景通过（包括离线补发与定时补发）。

风险等级：P1（默认配置下“离线/兜底补发”不生效，容易在测试/预期上误判为“丢消息”；若要提供可靠性能力需明确开启并做容量与安全评估）

### 高并发连接（基线）

使用脚本 `scripts/ws-load-test/run.ps1`（Java WebSocket 客户端）：

- `CONNECT` 模式：`clients=1000`（单实例 `9002`）
  - 连接成功：1000/1000
  - 鉴权成功：1000/1000

补充：在默认实例 `ws://127.0.0.1:9001/ws` 上做连接建立基线（短时，不含长稳态）：

- 2k：连接成功 2000/2000，鉴权成功 2000/2000
- 5k：连接成功 5000/5000，鉴权成功 5000/5000
- 10k：连接成功 10000/10000，鉴权成功 10000/10000

风险等级：P2（连接建立能力表现正常；但单机短时建立不等于“稳态承载/吞吐/抖动”能力，需要 soak 与消息压测补齐）

### 即时性（PING/PONG RTT 基线）

同样使用 `scripts/ws-load-test/run.ps1`：

- `PING` 模式：`clients=500`，持续 60s，间隔 1s
  - PING/PONG：29000/29000
  - RTT：P50=1ms，P95=3ms，P99=9ms

补充：默认实例（9001）在 `clients=2000`、30s、间隔 1s 的 RTT 基线：

- PING/PONG：47712/47710
- RTT：P50=1ms，P95=2ms，P99=3ms

风险等级：P2（单机本地 RTT 很好；跨机/跨网段/高写入/慢消费者场景需要单独验证）

### 重启可用性（演练样例）

用 `CONNECT + reconnect` 模式模拟“重连风暴”：

- 在压测过程中重启网关实例（9002）
- 观察到大量连接重试与失败（客户端侧缺少指数退避/退让时容易形成风暴）

建议将“客户端重连策略”纳入 SLO：必须指数退避 + 抖动 + 最大重试间隔，并在服务端侧做连接洪峰保护（限流/排队/熔断）。

风险等级：P1（重连风暴若缺少退避，会导致连接风暴；本次压测器已内置退避避免本机自打爆）

补充本次量化结果（500 连接、40s、期间重启一次 9002）：

- connect attempts=4000，connect ok=1000，connect fail=3000
- auth ok=1000

解读：短窗口内连接失败主要发生在端口不可用阶段；恢复后连接可重新建立，但重试量仍较高，建议继续下调重试频率并在服务端设置连接洪峰保护。

### Redis 短暂不可用（演练实测）

做了两次测试：

1) Redis 停止期间直接跑 `ws-smoke-test`（不自动恢复）：
- 结果：`basic/idempotency/offline_drop_and_recover/cron_resend_no_ack_receive/auth_chain/friend_request` 全部 timeout 失败（服务端在 Redis 不可用时出现明显可用性问题）。

2) Redis 只中断 10s 并恢复，然后再跑 `ws-smoke-test`：
- 结果：恢复后 `ws-smoke-test` 全场景通过（说明恢复后功能可回归）。

3) Redis 中断 10s（恢复）+ 期间运行 WS PING 压测（500 连接、60s、1s 间隔）：
- 结果：PONG 从 28000 降到 18135，RTT P99 升至 704ms（可见 Redis 抖动会显著影响 WS 即时性与丢包/超时）。

风险等级：P0（Redis 抖动导致即时性与可用性显著下降，应优先做：连接池超时/熔断/降级路径、fail-open 真正生效、关键链路去 Redis 依赖或异步化）

### 网络抖动（客户端断连重连）实测

使用压测器做“连接抖动”：1000 连接、每 2s 随机断开 20% 并重连，持续 60s：

- connect attempts=6296，connect ok=6276（无 connect fail）
- auth ok=6272

PING 模式同样抖动（500 连接、每 2s 断开 20%、60s）：

- RTT：P50=2ms，P95=29ms，P99=40ms
- PONG：26011/25495（轻微缺失）

风险等级：P2（在该规模下可用性尚可；更大规模或更弱网络需进一步压测）

### 慢消费者（不读/延迟读）实测

构造：单聊 E2E，200 连接（100 发、100 收），其中 30% 接收端每条消息延迟 5s 才 `request(1)` 读取。

- E2E 延迟：P50=23643ms，P95=46949ms，P99=51468ms
- 网关进程内存：接收侧实例（9001）WorkingSet 约从 208MB 增长到 416MB（短时间明显上涨）

风险等级：P1（存在被慢端拖垮/内存上涨/延迟爆炸风险；建议尽快补齐写缓冲水位/踢慢连接/按连接限速等保护）

#### 后续修复（2026-01-09，待回归量化）

已在服务端加入最小背压保护（不改变协议、不引入新中间件）：

- Netty childOption 增加 `WRITE_BUFFER_WATER_MARK`，让 `channel.isWritable()` 有意义（默认低/高水位：256KB/512KB）
- `WsWriter` 在连接 unwritable 时拒绝继续写入（避免出站缓冲无限堆积），并将门禁提前到调度前（避免向 eventLoop 堆积大量 pending tasks）
- 连接持续 unwritable 超过阈值后自动断开（默认 3s），并输出可观测日志：`ws backpressure: closing slow consumer channel`
- 生产侧补齐提前门禁：在线推送路径在不可写时对 critical 类型（`ERROR/CALL_*`）直接断开；补发在不可写时跳过该连接，避免补发洪峰放大积压

#### 回归量化（2026-01-09，多实例）

说明：以下均为 Windows 单机多实例（2 个网关进程）实测，数据仅用于回归对比，不代表容量上限。

1) 多实例路由/单端登录/跨实例群聊冒烟：通过
- `logs/bp-multi/ws_cluster_smoke_20260109_164010.json`（ok=true）

2) 应用层“延迟读取”（慢消费者）回归：快端与慢端解耦（低速率）

基线（无慢端，约 196.65 msg/s）：
- `logs/bp-multi/load_single_e2e_rate200_userbase_6628034_20260109_170150.json`
  - E2E：P50=185ms / P95=6647ms / P99=7266ms

慢端（30% 接收端每条延迟 5s 才读取，约 199.75 msg/s）：
- `logs/bp-multi/load_single_e2e_rate200_slow_userbase_8047514_20260109_170430.json`
  - 快端 E2E：P50=123ms / P95=466ms / P99=864ms
  - 慢端 E2E：P50=27565ms / P95=50251ms / P99=50679ms
- `logs/bp-multi/mem_rate200_slow_userbase_8047514_20260109_170430.csv`
  - WorkingSet：约 277MB → 477~529MB 后趋稳（60s 内未出现线性爬升）

结论：在低速率下，背压门禁不会让“慢端”拖垮整体；慢端自身延迟仍会变大（符合排队/不读的物理事实）。

3) 网络级“不读”触发 `channel.isWritable()` 翻转：已可复现“踢慢连接”闭环（大包 + 小水位）

触发参数（示例）：`BodyBytes=4000`、`BpLow/High=32/64KB`、`BpCloseAfterMs=1500ms`。

- 负载统计：
  - `logs/bp-multi/load_single_e2e_base_20260109_180108.json`
  - `logs/bp-multi/load_single_e2e_slow_20260109_180108.json`
  - `logs/bp-multi/load_single_e2e_noread_20260109_180108.json`
- 内存采样：
  - `logs/bp-multi/mem_gw-a_20260109_180108.csv`
  - `logs/bp-multi/mem_gw-b_20260109_180108.csv`
- 服务端证据（踢慢端）：
  - `logs/bp-multi/gw-b_20260109_180021.out.log`（日志关键字：`ws backpressure: closing slow consumer channel`，本次统计 closeSlow=20）

结论：在可触发 unwritable 的条件下，网关会在阈值内主动断开慢连接，避免其无限堆积出站缓冲。

补充观察：在该“大包 + 较高写入速率”配置下，E2E 分位数显著升高（秒级到十几秒级），主要反映 DB/落库/ACK 链路的排队能力上限，需要另行做吞吐与存储侧调优（不应归因于背压本身）。

回归验证建议（通过标准）：

- 同 `SlowConsumerPct=30/SlowConsumerDelayMs=5000` 重放 60s：
  - 网关 WorkingSet 不出现“持续线性爬升”
  - 普通收端 E2E P99 < 5s（慢端允许被主动断开或单独劣化，但不能拖垮整体）
- 如需要调参：优先调整 `im.gateway.ws.backpressure.write-buffer-*-water-mark-bytes` 与 `im.gateway.ws.backpressure.close-unwritable-after-ms`

本次代码级验证（不依赖 MySQL/Redis）：

- `mvn test`：25 tests, 0 failures, 0 errors（用于确保背压相关改动不破坏现有单元测试）

## 可复现命令（本机）

1) WS 冒烟（默认实例 9001）

- `scripts/ws-smoke-test/run.ps1`（参数：`WsUrl/HttpBase/JwtSecret/TimeoutMs/UserA/UserB`）

2) 第二实例启动（用于开启 cron 补发）

- `java -jar target/mini-im-0.0.1-SNAPSHOT.jar --server.port=8081 --im.gateway.ws.port=9002 --im.cron.resend.enabled=true --im.cron.resend.fixed-delay-ms=2000`

## 2026-01-09 多实例（本机）背压专题复测（基于现有脚本）

说明：本段为“多实例 + 慢消费者”复测记录，用于回归与对比，不代表生产容量上限。

### 多实例 WS 冒烟（跨实例路由）

使用 `scripts/ws-cluster-smoke-test/run.ps1` 启动两实例后验证：

- 断言通过：登录/单端登录踢下线（KICK）/单聊跨实例投递/群聊跨实例投递
- 实测输出文件（JSON）：`logs/bp-multi/ws_cluster_smoke_20260109_164010.json`

### 慢消费者（低速率 200 msg/s，30% 接收端延迟 5s）

为避免 DB 历史数据（离线补发）污染 E2E 统计，本次每次运行使用新的 `-UserBase` 区间。

- 运行命令（示例）：
  - `powershell -ExecutionPolicy Bypass -File scripts/ws-load-test/run.ps1 -Mode single_e2e -WsUrls ws://127.0.0.1:<wsA>/ws;ws://127.0.0.1:<wsB>/ws -RolePinned -Clients 200 -DurationSeconds 60 -MsgIntervalMs 500 -UserBase <random> -SlowConsumerPct 30 -SlowConsumerDelayMs 5000`
- 实测结果（`UserBase=8047514`，见输出文件）：
  - 发送速率：约 199.75 msg/s（sent=11985/60s）
  - 快端（非慢消费者）E2E：P50=123ms，P95=466ms，P99=864ms
  - 慢端 E2E：P50=27565ms，P95=50251ms，P99=50679ms
  - 汇总 E2E：P99=37149ms（被慢端拖高，属预期；因此需要拆分统计）
  - 输出文件：`logs/bp-multi/load_single_e2e_rate200_slow_userbase_8047514_20260109_170430.json`
  - 内存采样（WorkingSet，2s 间隔，见 CSV）：A: 277MB→~529MB 后趋稳；B: 277MB→~477MB 后趋稳（非线性持续爬升）
    - `logs/bp-multi/mem_rate200_slow_userbase_8047514_20260109_170430.csv`
  - 背压踢慢端：本次未触发 `ws backpressure: closing slow consumer channel`（更像“应用层延迟读取”，未必等价于 TCP 层不读/网差，需用更强的网络级慢端模拟复验）

### 基线（低速率 200 msg/s，无慢消费者）

- 运行命令（示例）：
  - `powershell -ExecutionPolicy Bypass -File scripts/ws-load-test/run.ps1 -Mode single_e2e -WsUrls ws://127.0.0.1:<wsA>/ws;ws://127.0.0.1:<wsB>/ws -RolePinned -Clients 200 -DurationSeconds 60 -MsgIntervalMs 500 -UserBase <random>`
- 实测结果（`UserBase=6628034`，见输出文件）：E2E P50=185ms，P95=6647ms，P99=7266ms
  - `logs/bp-multi/load_single_e2e_rate200_userbase_6628034_20260109_170150.json`

3) WS 冒烟（第二实例 9002）

- 将 `WsUrl`/`HttpBase` 改为 `ws://127.0.0.1:9002/ws`、`http://127.0.0.1:8081`

4) 连接/心跳基线

- `scripts/ws-load-test/run.ps1 -Mode connect -WsUrl ws://127.0.0.1:9002/ws -Clients 1000 -DurationSeconds 30`
- `scripts/ws-load-test/run.ps1 -Mode ping -WsUrl ws://127.0.0.1:9002/ws -Clients 500 -DurationSeconds 60 -PingIntervalMs 1000`

5) 网络抖动（断连重连）

- `scripts/ws-load-test/run.ps1 -Mode connect -WsUrl ws://127.0.0.1:9002/ws -Clients 1000 -DurationSeconds 60 -Reconnect -FlapIntervalMs 2000 -FlapPct 20`
- `scripts/ws-load-test/run.ps1 -Mode ping -WsUrl ws://127.0.0.1:9002/ws -Clients 500 -DurationSeconds 60 -Reconnect -FlapIntervalMs 2000 -FlapPct 20`

6) 慢消费者

- `scripts/ws-load-test/run.ps1 -Mode single_e2e -WsUrls ws://127.0.0.1:9002/ws;ws://127.0.0.1:9001/ws -RolePinned -Clients 200 -DurationSeconds 60 -MsgIntervalMs 100 -SlowConsumerPct 30 -SlowConsumerDelayMs 5000`
